{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI勉強会V1",
      "provenance": [],
      "collapsed_sections": [
        "Mmx0g2eG6NXt",
        "g5PqkPWW1nz7"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nstshirotays/Study-AI/blob/master/AI%E5%8B%89%E5%BC%B7%E4%BC%9AV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-USdFhOfX6MW",
        "colab_type": "text"
      },
      "source": [
        "# AI勉強会\n",
        "この勉強会では O'REILLY「ゼロから作る Deep Learning」について解説を行い内容の理解を深めることを目的としている。\n",
        "\n",
        "## 本日のキーワード\n",
        "* 活性化関数はリールー\n",
        "* 出力層はソフトマックス\n",
        "* 損失関数は交差エントロピー\n",
        "* 底を見つけるのが勾配降下法\n",
        "* 学習率は当て推量\n",
        "* イテレーション数はPDCAの繰り返し回数\n",
        "* 計算機の能力に合わせて、一回に処理する複数のデータをミニバッチ\n",
        "* ミニバッチの総和が全量と等しいとき、１エポック\n",
        "\n",
        "<hr>\n",
        "学習の準備として下記を実行して下さい\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-PZLcS7KCHW",
        "colab_type": "code",
        "outputId": "b653d888-90dd-4ef8-f6fb-665be4f38de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/oreilly-japan/deep-learning-from-scratch.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 414 (delta 1), reused 2 (delta 0), pack-reused 404\u001b[K\n",
            "Receiving objects: 100% (414/414), 5.51 MiB | 26.49 MiB/s, done.\n",
            "Resolving deltas: 100% (209/209), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfqLQnfynLnC",
        "colab_type": "text"
      },
      "source": [
        "# パーセプトロン\n",
        "ハイ・ローの電気信号による演算を行うCPUの内部構成は、ANDやOR演算を行う論理素子の集合体である。心理学者・計算機科学者のフランク・ローゼンブラットは、人間の脳内でもこのような演算素子と同様のプロセスが、生物学的原理で動作すると想定した。そして実際に回路を作成し画像の学習処理を行った（1957年）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3ihZ8xE6aCN",
        "colab_type": "text"
      },
      "source": [
        "## パーセプトロンの概要\n",
        "\n",
        "\n",
        "![論理記号](https://docs.google.com/drawings/d/e/2PACX-1vQ2SKuRbOhYXSsd1vbFCWV3iJzEBX2LUoM6QSHY6jpWt1hiOzBMgbzeRm-Pqs5yS-qdAoZBO57Jxr4G/pub?w=390&h=365)\n",
        "\n",
        "電気回路的な演算素子はそれぞれに実体が異なるが、脳内ではすべて同様の組織体から構成されると想定し、同一の細胞（ニューロン）が外部のコントロールにより様々な２値（真偽値）を出力すると考察し、まずはニューロンを下記のようにモデル化した。\n",
        "\n",
        "![ニューロンモデル](https://docs.google.com/drawings/d/e/2PACX-1vSinEodXTx3n5L_cMTGqzbDcKC1y6ncEjm0vjk5wHCiDPIT476aqJxuNiiniflzJvy0zjylvyEz0vTP/pub?w=302&h=75)\n",
        "\n",
        "\n",
        "この円形はニューロンを表す。ニューロンへの入力は矢印で表され、それぞれの入力信号に対して重み付けがされる。これらの情報を元にニューロンYは入力データに重みを乗算した値を閾値θと比較して出力を０か１の二値に振り分ける。これを一般化し下記のような構成にしたものがパーセプトロンである。\n",
        "\n",
        "![パーセプトロン](https://docs.google.com/drawings/d/e/2PACX-1vSpMVD85wOprci70XqNYFpaA3gNI_rTRVezumjEJ6trAHQ6qMq7gPA-PH7bDzHfOkMb-pEKQXxSOvs_/pub?w=302&h=220)\n",
        "\n",
        "パーセプトロンでは、複数のニューロンからの入力値（X1、X2、、、）にそれぞれの重み（W1、W2、、、、）を掛けた値を合算し、さらに前述のモデルで閾値θを外部からの入力値として引き出す。これをバイアスと改めて再定義し、それらの総合計がゼロ以下であればゼロを、そうでなければ１を結果として出力するというモデルである。\n",
        "\n",
        "CPUにおける演算素子はそれぞれ固有のデバイスであるが、このパーセプトロンでは信号の重みであるWとバイアス値であるｂの値を工夫することで、ニューロンの構成を変えずにAND、OR、NANDの演算を行うことができる。\n",
        "\n",
        "この発見により、神経伝達をそのモデルとしたパーセプトロンはコンピューターのCPUと等価と見なせる事となり、人間の脳活動をコンピューターで摸倣できる可能性が示された。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-RfG8FikpGb",
        "colab_type": "text"
      },
      "source": [
        "## ANDパーセプトロンの例\n",
        "X1とX2のAND（論理積）Yは以下の表の通りとなる。\n",
        "\n",
        "![真理値（AND)](https://docs.google.com/drawings/d/e/2PACX-1vRBDAVLdjYPZdwKgzW7KjJChXCcVpuf2F4BV37uJsMeq9RiKaEOiBm1ku6IWWPfIIAoYMAsXsFP5y4r/pub?w=110&h=104)\n",
        "\n",
        "これをパーセプトロンで実現する場合は例として下記のように重みWとバイアスｂを設定する。\n",
        "\n",
        "![ANDパーセプトロン](https://docs.google.com/drawings/d/e/2PACX-1vS0_fzuAskoeaRAzwEG5YW7YVbXQbVppfbPCA64l-KFjYmMjRuCpsCgvR1Y-k2p24j3Ods_0WE_NumA/pub?w=302&h=220)\n",
        "\n",
        "\n",
        "実際にpythonで実装を行う。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwcofQZYpQ7i",
        "colab_type": "code",
        "outputId": "27f98ce6-184b-4bc4-82fc-c6eb0f9b8ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import numpy as np    # 行列演算の為のライブラリの読み込み\n",
        "\n",
        "#---------------------------\n",
        "#  論理積を計算する\n",
        "#---------------------------\n",
        "def AND(x1,x2):\n",
        "  x = np.array([x1,x2])\n",
        "  w = np.array([0.5,0.5])\n",
        "  b = -0.7\n",
        "  result = b + np.sum(w*x)\n",
        "  if result <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "  \n",
        "print(AND(0,0))\n",
        "print(AND(0,1))\n",
        "print(AND(1,0))\n",
        "print(AND(1,1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ycu4loorf6r",
        "colab_type": "text"
      },
      "source": [
        "## ORパーセプトロン\n",
        "先程のANDパーセプトロンの重みWとバイアスｂを変更することでor（論理和）パーセプトロンも実装できる。\n",
        "\n",
        "ORパーセプトロンの真偽値は下記の通り\n",
        "\n",
        "![ORパーセプトロン](https://docs.google.com/drawings/d/e/2PACX-1vT5n56HwMBreq9nmHCYS3rydXTPR3YQRXs62---PUy9PV6hyP6uSNDVN6A63I-KLN3whl6YPsMwCWYP/pub?w=110&h=104)\n",
        "\n",
        "これをパーセプトロンで実現する場合は例として下記のように重みWとバイアスｂを設定する。\n",
        "* W1 = 0.5\n",
        "* W2 = 0.5\n",
        "* b = -0.2\n",
        "\n",
        "これを同様にpythonで実装する\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaVNUoQ8tVPm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzrYtfH9sySp",
        "colab_type": "code",
        "outputId": "f99dddc5-801e-4c08-ba72-25f4f5db39a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#---------------------------\n",
        "#  論理和を計算する\n",
        "#---------------------------\n",
        "def OR(x1,x2):\n",
        "  x = np.array([x1,x2])\n",
        "  w = np.array([0.5,0.5])\n",
        "  b = -0.2\n",
        "  result = b + np.sum(w*x)\n",
        "  if result <= 0:\n",
        "    return 0\n",
        "  else:p\n",
        "    return 1\n",
        "  \n",
        "print(OR(0,0))\n",
        "print(OR(0,1))\n",
        "print(OR(1,0))\n",
        "print(OR(1,1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbrDEEzDtYfg",
        "colab_type": "text"
      },
      "source": [
        "## アルゴリズムとしてのパーセプトロン\n",
        "上記と同様にNANDなども表現できる。さらにこれらのパーセプトロンを複数組み合わせることもできる。これにより単層では表現できないXORなどの論理演算も可能となる。\n",
        "\n",
        "最も重要な点は、このパーセプトロンを構成する一つ一つのニューロンは全て等価であり、単に入力値への重み付けが異なるだけという点である。\n",
        "\n",
        "よってパーセプトロンではこの重みの値を決定することで演算が可能となり、これは演算アルゴリズムをパーセプトロンの重みで表現しているとも言い換えることができる。\n",
        "\n",
        "これまでのコンピューティングはオブジェクト指向であれなんであれ、実体としては命令を逐次実行することで目的を達成している。AIでは情報を伝達するためのプログラムは存在するが、実際の判定ロジックそのものはこの「重み」が担っている。\n",
        "\n",
        "ただし単層のパーセプトロンではXOR回路が生成出来ないことが指摘され、多層パーセプトロンが開発されたものの、そのままでは線形分離不可能なパターンを識別できないことが指摘さた。さらに、重みパラメータの設定方法が不明であったことも大きな問題点であった。このためその後10年にわたってこのパーセプトロン理論は日の目を見ることができなかった。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL-874h9wjIz",
        "colab_type": "text"
      },
      "source": [
        "# ニューラルネットワーク\n",
        "パーセプトロンのコンセプトを元に、これに改良を加えたものがニューラルネットワークである。\n",
        "* 活性化関数の導入\n",
        "* ３層構造の導入（出力層の工夫）\n",
        "* 機械学習(ディープラーニング）の導入\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmx0g2eG6NXt",
        "colab_type": "text"
      },
      "source": [
        "## 活性化関数の導入\n",
        "パーセプトロンはもともと二値演算を生物学的に実現しようという発想であったため、出力値は当然２値である。これをデジタル（離散値）ではなくアナログ（連続値）にもちこんだのが、このニューラルネットワークの優れた着想点である。\n",
        "\n",
        "ニューラルネットワークでは、これを活性化関数として再定義している。\n",
        "\n",
        "\n",
        "主な活性化関数を下記に示す\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQzVnI_66Oz1",
        "colab_type": "text"
      },
      "source": [
        "### ステップ関数\n",
        "パーセプトロンで実装されている方式。\n",
        "\n",
        "評価式の結果がゼロ以下かそれ以外で０、１の二値を返す\n",
        "\n",
        "ステップ関数をグラフに表示する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzO1oCsJ1ykU",
        "colab_type": "code",
        "outputId": "784b906b-95d6-4569-fb51-86479d40caa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "#------------------------\n",
        "# ステップ関数\n",
        "#------------------------\n",
        "def step_function(x):\n",
        "    return np.array(x > 0, dtype=np.int)\n",
        "\n",
        "#------------------------\n",
        "# グラフへの表示\n",
        "#------------------------\n",
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "Y = step_function(X)\n",
        "plt.plot(X, Y)\n",
        "plt.ylim(-0.1, 1.1)  # 図で描画するy軸の範囲を指定\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3AGghQh3AGghwh0AWohwB4AW+n9SUyHBkOuTZAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5PqkPWW1nz7",
        "colab_type": "text"
      },
      "source": [
        "### シグモイド関数\n",
        "初期のニューラルネットワークで広く用いられた関数。\n",
        "\n",
        "（城田説）ステップ関数に近い連続的で微分しやすい関数を使ったと思ってる\n",
        "\n",
        "\n",
        "![シグモイド関数](https://docs.google.com/drawings/d/e/2PACX-1vSPiq7ffbs0PiyFDXrg93J1t3KdMq0eAnCoVC_JfD62LrszzR9t_4c3U76pF_SvNhDCxeKplvJrBIL_/pub?w=182&h=100)\n",
        "\n",
        "グラフに表示する。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0yf1TAL2g0P",
        "colab_type": "code",
        "outputId": "fc5b2791-cda5-4d61-cd06-04fe3cd37bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "#------------------------\n",
        "# シグモイド関数\n",
        "#------------------------\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))    \n",
        "\n",
        "#------------------------\n",
        "# グラフへの表示\n",
        "#------------------------\n",
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "Y = sigmoid(X)\n",
        "plt.plot(X, Y)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndxGREKRyFxEJQSp3EZEQ9P8A9nnclg8mQC4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biLbM0kG1qqO",
        "colab_type": "text"
      },
      "source": [
        "上記のようにシグモイド関数では、結果は２値ではなく０から１までの実数が返却される。\n",
        "\n",
        "これは出力値を２つに限定したパーセプトロンからの大きな飛躍であり、これにより複雑な（曖昧な）入力と出力が可能となった。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLC6sU0y4ARZ",
        "colab_type": "text"
      },
      "source": [
        "### ReLU関数　（別名：ランプ関数　　ramp func 傾斜関数）\n",
        "最近のAIではシグモイド関数の代わりに用いられる事が多い。\n",
        "\n",
        "ReLUは入力値がゼロを超えていればそのまま出力される。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEAtGJId5cji",
        "colab_type": "code",
        "outputId": "2c3f6598-8082-4ffc-efd6-9365d6e8baa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "#------------------------\n",
        "# ReLU関数\n",
        "#------------------------\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "#------------------------\n",
        "# グラフへの表示\n",
        "#------------------------\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = relu(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-1.0, 5.5)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8VyVbpH6pvs",
        "colab_type": "text"
      },
      "source": [
        "## 3層構造の導入\n",
        "ニューラルネットワークでは、全体のネットワーク構造（ニューロンの繋がり）を入力層、中間層、出力層の３種類で定義している。\n",
        "\n",
        "下記に３層構造のニューラルネットワークを図示する（入力層が０番目）。\n",
        "\n",
        "![ニューラルネットワーク図](https://docs.google.com/drawings/d/e/2PACX-1vTz9IG4wquQ4WPAyi6vaxoMVAnO_g1E7lA3We7u1x84faTg_pUQ3KWwEuyP-NDn9YQnPu694SUXM12t/pub?w=960&h=720)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFWbHevF_Gl-",
        "colab_type": "text"
      },
      "source": [
        "### 入力層\n",
        "ニューラルネットワークの入力となる層。\n",
        "\n",
        "各ニューロンへの値は一つなので、画像を認識しようとすれば、各画素毎の値が入力値となる。\n",
        "\n",
        "具体的には縦横１６ドットの画像であれば、１６×１６＝２５６の画素で構成されるため、入力層のニューロンは２５６個必要となる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GTLGjAsABCf",
        "colab_type": "text"
      },
      "source": [
        "### 隠れ層\n",
        "この層がAIにおけるモデルの中心部分であり日々進化を遂げている。\n",
        "\n",
        "過去には計算機のパワー不足により隠れ層が１つでも多大な負荷であったが、現在ではこの隠れ層を数百に及んで実装することも可能となっている。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgO6jmr__wS0",
        "colab_type": "text"
      },
      "source": [
        "### 出力層\n",
        "ニューラルネットワークの出力となる層。この層の設計は説かれる問題によってニューロンの個数と活性化関数が決まってくる（このため、先程の図では出力層での活性化関数がh()ではなくσ()と記述している）。\n",
        "　　\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>問題の種類</th>\n",
        "    <th>問題の例</th>\n",
        "    <th>活性化関数</th>\n",
        "    <th>出力層の数</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>回帰問題</td>\n",
        "    <td>年齢推定など特定の値を求める</td>\n",
        "    <td>恒等関数</td>\n",
        "    <td>1個</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>２値分類</td>\n",
        "    <td>合格・不合格など２種類に分類する</td>\n",
        "    <td>シグモイド関数</td>\n",
        "    <td>2個</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>多クラス問題</td>\n",
        "    <td>文字認識など複数のクラスに分解する問題</td>\n",
        "    <td>ソフトマックス関数</td>\n",
        "    <td>n個</td>\n",
        "  </tr>\n",
        "</table>\n",
        "</br>\n",
        "\n",
        "\n",
        "今回の手書き数字認識であれば、結果は０から９のいずれかになるので、出力層は１０となり出力層での活性化関数はソフトマックス関数を用いる。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2hRLitDC5hY",
        "colab_type": "text"
      },
      "source": [
        "#### ソフトマックス関数\n",
        "![ソフトマックス関数](https://docs.google.com/drawings/d/e/2PACX-1vSzbhHIZVMWV4YAJgndvhJuHOmPNSNBJYlKqpLh1d0Ffl6Lfbr9HcQcczLk-oWQgYqcno_Mn6TuFAaM/pub?w=185&h=100)\n",
        "\n",
        "この関数は出力値を全体の合計値で割ることにより、必ず０～１の間における割合を示す。これは擬似的に出力値に対する期待度、信頼度を示しているとも言える。\n",
        "\n",
        "なお、expをしていることにより、出力値が高い場合はより大きい値をとることで、微細な違いもはっきりと表示する効果を持っている。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npN6fdBEGp20",
        "colab_type": "text"
      },
      "source": [
        "## 手書き数字（エムニスト）認識の実装\n",
        "それでは、実際にニューラルネットワークを使って手書き文字認識を実装してみる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsgiudRhHFSm",
        "colab_type": "text"
      },
      "source": [
        "### エムニストデータセット\n",
        "oreillyのデータを使ってMNISTデータの認識を行う\n",
        "\n",
        "![MNIST](https://docs.google.com/drawings/d/e/2PACX-1vRmKtGjrW_McthMyjLw9dj_zXxKaZ-Gca_HeNPKumeS7EIZ72ndBVYITGC0VLaRQOcayx97xOt_f40n/pub?w=289&h=173)\n",
        "\n",
        "Mixed Natioal Institute of Standards and Technology database. MNIST [エムニスト] [em-nist]\n",
        "\n",
        "\n",
        "![サンプル](https://docs.google.com/drawings/d/e/2PACX-1vQkslZu9xyboXsva9jgmQDVrynTZZeYnI6yMamdc012Y3z5kTrA68ePcAyBsagxSfyawIsTHhFE-b7j/pub?w=290&h=318)\n",
        "\n",
        "* サイズは２８×２８ドット\n",
        "* 白黒２５６階調（０白：２５５：黒）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I7etWIjtj4R",
        "colab_type": "text"
      },
      "source": [
        "### ニューラルネットワークの設計\n",
        "ここでは隠れ層を２つもつニューラルネットワークを構築する\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vQPJZS9d6upJkCh2yHAc7h5620ZZCjPvGNzHuOTyrXx1kYv8HCC5ORtbB-6FQC-E4oir0peQFe-Q5k9/pub?w=1291&h=743)\n",
        "\n",
        "* 入力層は２８×２８＝７８４個のニューロン\n",
        "* 隠れ層１は５０個のニューロン\n",
        "* 隠れ層２は１００個のニューロン\n",
        "* 出力層は（正解が0～9なので）１０個のニューロン\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-JgC20YPdz5",
        "colab_type": "code",
        "outputId": "1f08ca88-2ef4-464a-a2a7-d3d1d120d639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd /content/deep-learning-from-scratch/ch03\n",
        "\n",
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import pickle\n",
        "from dataset.mnist import load_mnist\n",
        "from common.functions import sigmoid, softmax\n",
        "\n",
        "#-----------------------------\n",
        "# データの取得\n",
        "#-----------------------------\n",
        "def get_data():\n",
        "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "    return x_test, t_test\n",
        "\n",
        "\n",
        "#-----------------------------\n",
        "# 定義済みのニューラルネットワークの読み込み\n",
        "#-----------------------------\n",
        "def init_network():\n",
        "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
        "        network = pickle.load(f)\n",
        "    return network\n",
        "\n",
        "\n",
        "#-----------------------------\n",
        "# 推論処理\n",
        "#-----------------------------\n",
        "def predict(network, x):\n",
        "    # 重み配列の読み込み\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    # バイアスの読み込み\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    # 入力層　-> 隠れ層1　の処理\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "\n",
        "    # 隠れ層1　-> 隠れ層2　の処理\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "\n",
        "    # 隠れ層2　-> 出力層　の処理\n",
        "    a3 = np.dot(z2, W3) + b3\n",
        "    y = softmax(a3)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "#-----------------------------\n",
        "# メイン処理\n",
        "#-----------------------------\n",
        "x, t = get_data()             # 入力データx と正解データt を読み込む\n",
        "network = init_network()      # 訓練済みの重み、バイアスデータを読み込む\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(len(x)):\n",
        "    # 一枚ごとに推論処理を行う\n",
        "    y = predict(network, x[i])\n",
        "    p= np.argmax(y)           # 最も確率の高い要素のインデックスを取得\n",
        "    if p == t[i]:\n",
        "        # 正解の場合\n",
        "        accuracy_cnt += 1\n",
        "\n",
        "#-----------------------------\n",
        "# 結果表示\n",
        "#-----------------------------\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch/ch03\n",
            "Accuracy:0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em0jNpA-XQxM",
        "colab_type": "text"
      },
      "source": [
        "### バッチ処理の実装\n",
        "上記の例は６万枚の画像データについて一枚づつ処理を行っている。\n",
        "\n",
        "numpyなどの科学計算ライブラリは行列計算が高速に行えるようにチューニングされている。このため一般的にはロジックでループ処理を行うより、行列式として一度に計算する量を増やしてやるほうが結果として処理が早くなる。\n",
        "\n",
        "今回の例では一つの画像データ（画素数分の列データ）を複数画像分まとめて（行列データにして）渡すことで、計算が早くなる。\n",
        "\n",
        "このまとめる指定を「バッチ（束）」と呼ぶ。\n",
        "\n",
        "バッチ数を指定した場合のプログラムを下記に示す（結果は変わらない）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXwJLKQPXNKQ",
        "colab_type": "code",
        "outputId": "d5f00fee-8d74-4bc6-c717-ec0d28afc429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "batch_size = 100 # バッチの数\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size):\n",
        "    x_batch = x[i:i+batch_size]\n",
        "    y_batch = predict(network, x_batch)\n",
        "    p = np.argmax(y_batch, axis=1)\n",
        "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-zpOiF0bBxT",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning\n",
        "ディープラーニングとは４層以上のニューラルネットワークにおける各パラメータ（重み、バイアス）を決定する作業である。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-sUaSzaX5Ej",
        "colab_type": "text"
      },
      "source": [
        "## Learning概要\n",
        "具体的な処理手順をPDCAに例えると、Pとして対象データ郡を抽出し、Dとしてニューラルネットの計算を行う。次にCとして結果の評価を行い、Aとしてパラメータの再設定を行う。これを必要回数分行う。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPoM_jYM9060",
        "colab_type": "text"
      },
      "source": [
        "## P:対象データの抽出-ミニバッチ\n",
        "ミニバッチとは全量データを使わずに一部のデータをランダムに抜き出すことで処理の高速化を図るテクニックである。これはTV局の視聴率調査と同様の考え方に基づいている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP_Rg3f2DCic",
        "colab_type": "text"
      },
      "source": [
        "## D:ニューラルネットの計算\n",
        "ミニバッチで抽出されたデータを使ってニューラルネットを計算する。これは先に述べたように、中間層の活性化関数をシグモイド関数とし、出力層ではそれをソフトマックスにより確率として計算される。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEl8IIEkdVl9",
        "colab_type": "text"
      },
      "source": [
        "## C:チェック：損失関数の設定\n",
        "ソフトマックスにより計算された値がどの程度正解からズレているか（誤差）を計算する。この関数を損失関数と呼ぶ。\n",
        "\n",
        "損失関数は誤差を数値化することである。数学的に最も有名な誤差計測の方法は２乗和誤差と呼ばれるものであるが、AIの世界では交差エントロピー誤差という手法が利用される。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1y-z9kQAPRa",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### 交差エントロピー誤差\n",
        "![交差エントロピー誤差](https://docs.google.com/drawings/d/e/2PACX-1vRkLbMfJmj-vUDumOXr1Lxk32H9Hu7CNryVJWggm48BZmN8pMkEfX94XdkzyaAiggbWiqrBRTdteCBv/pub?w=150&h=100)\n",
        "\n",
        "　先のmnistデータでは、各画像に対する正解データ（教師データ）は０から９までの配列で表されていた。  \n",
        "　一方、ニューラルネットワークを使って計算された出力結果はソフトマックス関数により０から１までの値として表現される。  \n",
        "　この例で交差エントロピー誤差を計算すると、教師データは正解以外はゼロであるため、結局の所　E=log(0.8)を計算するだけでよい。\n",
        " \n",
        "<table>\n",
        "  <tr>\n",
        "    <th>ラベル</th>\n",
        "    <th>0</th>\n",
        "    <th>1</th>\n",
        "    <th>2</th>\n",
        "    <th>3</th>\n",
        "    <th>4</th>\n",
        "    <th>5</th>\n",
        "    <th>6</th>\n",
        "    <th>7</th>\n",
        "    <th>8</th>\n",
        "    <th>9</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th>正解データ</th>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>1</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th>SoftMax出力値</th>\n",
        "    <td>0</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0.8</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th>交差エントロピー誤差</th>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0.22</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "    <td>0</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "ちなみに、y = log(x)のグラフは"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfa-921_knha",
        "colab_type": "code",
        "outputId": "a7ccc737-254c-46f6-e7f1-110831c927f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "#------------------------\n",
        "# グラフ表示\n",
        "#------------------------\n",
        "x = np.arange(0.0001, 1.0, 0.01)\n",
        "y = np.log(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-5.0, 0.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOQW5iIjLKchFRFxOQS4i4nL/H9GNwUjJxw+EAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcNS1DahlVey",
        "colab_type": "text"
      },
      "source": [
        "となり、Xが１のときにYは０となる。なお、Xが０となるとlog(x)は-∞となるため、プログラミングする際はXがゼロとならないように極小のバイアス値を付加して算出する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUPCEsdrEXHV",
        "colab_type": "text"
      },
      "source": [
        "## A:パラメーターの再計算\n",
        "先に導出された損失関数を指標に各パラメーター（重みとバイアス）を決定してゆく。\n",
        "\n",
        "この値の決定方法として勾配降下法と呼ばれる手法が用いられる。\n",
        "\n",
        "### 勾配降下法\n",
        "\n",
        "まず一つのニューロンの重みWについて考えてみる。この重みを横軸にとり、縦軸に損失関数を表示した場合は下記のような図になるだろう。下図の曲線はデタラメであるものの、実際の値はもっと複雑なグラフにもなることであろう。\n",
        "\n",
        "\n",
        "![勾配降下法](https://docs.google.com/drawings/d/e/2PACX-1vRN5EFodaLfgY0qFOPS9jQLNnJFa-e5JnrwZBAEAVqAtdxPtdnFIhW3xN0176LokS0BbOm3IsdLmCVn/pub?w=791&h=386)\n",
        "\n",
        "ここでのポイントは、現時点でPで示される重みをどのように変化させたら損失関数の値が一番減るのだろうかという問題である。答えとしては点Pを増大させればよいことが、グラフを見ればすぐに分かる。\n",
        "\n",
        "これを数学的に置き換えるならば、**「傾きを下る」方向に値を調整する** という回答になる。\n",
        "\n",
        "\n",
        "この傾きを求めるには　点Pの前後のウェイト値を使って再度損失関数の値を求め、その差を使って傾きを求める方法がある。これを**数値微分**と呼ぶ。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yBy0Hh5v66J",
        "colab_type": "text"
      },
      "source": [
        "### 勾配降下法の例題\n",
        "実際に数値微分を使って勾配降下法の動きを見てみる。\n",
        "\n",
        "例として　　f(x1,x2) = x1^2 + x2^2 としたとき、関数fが最小の値となるx1,x2を求める。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLZnPuQPvcf5",
        "colab_type": "code",
        "outputId": "9a11de6c-63ed-42d1-a1e5-9a106e2f5042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "%cd /content/deep-learning-from-scratch/ch04\n",
        "\n",
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from gradient_2d import numerical_gradient\n",
        "\n",
        "\n",
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "    x = init_x\n",
        "    x_history = []\n",
        "\n",
        "    for i in range(step_num):\n",
        "        x_history.append( x.copy() )\n",
        "\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "\n",
        "    return x, np.array(x_history)\n",
        "\n",
        "\n",
        "def function_2(x):\n",
        "    return x[0]**2 + x[1]**2\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])    \n",
        "\n",
        "lr = 0.1               # Learning Rate 学習率\n",
        "step_num = 20\n",
        "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
        "\n",
        "plt.plot( [-5, 5], [0,0], '--b')\n",
        "plt.plot( [0,0], [-5, 5], '--b')\n",
        "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
        "\n",
        "plt.xlim(-3.5, 3.5)\n",
        "plt.ylim(-4.5, 4.5)\n",
        "plt.xlabel(\"X0\")\n",
        "plt.ylabel(\"X1\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch/ch04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpyIxXvhx6RC",
        "colab_type": "text"
      },
      "source": [
        "### 学習率(Learning Rate)η\n",
        "ここで重要なパラメータとして「学習率η（イータ）」がある。この学習率は傾きに乗じる定数であるが、これが大きすぎても小さすぎても正しい値を導くことができない。\n",
        "\n",
        "* lr=0.1であれば収束する\n",
        "* lr=0.01では収束しない\n",
        "* 逆にlr=0.8であると発散してしまう\n",
        "\n",
        "なお、この学習率は経験的に発見するしかない。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJHpaRxXy6SL",
        "colab_type": "text"
      },
      "source": [
        "## Learningの実装\n",
        "これまでの説明でPDCAを見てきた。ここで実際にプログラムとしてニューラルネットワークの学習を実装する。\n",
        "\n",
        "### 回数に関する用語\n",
        "\n",
        "PDCAの繰り返し回数を　**イテレーション数**と呼ぶ。\n",
        "\n",
        "\n",
        "対象としている訓練データの総数を１エポックという単位で表す。これはPDCAがミニバッチによりランダムに選ばれたデータで訓練をされるため、実際には全部のデータを処理したことにはならないが、便宜的に１エポックで一回りの学習をしたとみなすためである。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWfKRhNW-pab",
        "colab_type": "code",
        "outputId": "a176d244-9505-4bb0-bc9a-6b488466a639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "%cd /content/deep-learning-from-scratch/ch04\n",
        "\n",
        "\n",
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "# データの読み込み\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000  # 繰り返しの回数を適宜設定する\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 勾配の計算\n",
        "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "    \n",
        "    # パラメータの更新\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "    \n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
        "\n",
        "# グラフの描画\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, label='train acc')\n",
        "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch/ch04\n",
            "train acc, test acc | 0.09736666666666667, 0.0982\n",
            "train acc, test acc | 0.7874833333333333, 0.7906\n",
            "train acc, test acc | 0.87525, 0.8792\n",
            "train acc, test acc | 0.8983, 0.8996\n",
            "train acc, test acc | 0.9071666666666667, 0.9111\n",
            "train acc, test acc | 0.9129, 0.9165\n",
            "train acc, test acc | 0.9191, 0.9206\n",
            "train acc, test acc | 0.9233, 0.9255\n",
            "train acc, test acc | 0.9266333333333333, 0.9271\n",
            "train acc, test acc | 0.92985, 0.9316\n",
            "train acc, test acc | 0.93195, 0.9332\n",
            "train acc, test acc | 0.9353333333333333, 0.9371\n",
            "train acc, test acc | 0.9381, 0.9379\n",
            "train acc, test acc | 0.9402666666666667, 0.9393\n",
            "train acc, test acc | 0.94175, 0.9405\n",
            "train acc, test acc | 0.9445833333333333, 0.9428\n",
            "train acc, test acc | 0.9460666666666666, 0.9437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0k1FQUREuqkoiIhINxUFERHp9v8Bz7AwillwfFYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01_h0GkeKNBm",
        "colab_type": "text"
      },
      "source": [
        "# 誤差逆伝播法（バックプロパゲーション）\n",
        "　先程の機械学習では数値微分という方法で重みを計算したが、CPU処理量が多いため多層ネットワークの構築には不向きである。このため、計算が高速となる誤差逆伝播法（バックプロパゲーション）が開発された。  \n",
        "　多層に渡った活性化関数を微分するためには、連鎖率を利用して損失関数の値から逆向きに偏微分してゆくことで高速に計算できる。ここではそれを計算グラフにて説明する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8kuqguNcIH",
        "colab_type": "text"
      },
      "source": [
        "## 計算グラフ\n",
        "　計算グラフという記法を使い、順方向の計算を確認する\n",
        "\n",
        "![計算グラフ](https://docs.google.com/drawings/d/e/2PACX-1vTwwOt7w-NMp-xaUtPVC7ItTlS5IWqvm0IGxWJAQuWD1WSDNrJdowzxfQ9ED53x05uX26WEmkQjt6BL/pub?w=813&h=521)\n",
        "\n",
        "\n",
        "　この計算グラフを使ってリンゴの値段に関する合計金額の微分を求める。つまりリンゴ１個の値段が与える合計金額への影響度は下図のように示される。\n",
        "\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vQRRJ8owch1DvuUawwqgJ_hLX61YB5Lyt4exjIwP6bNnlPawfjN12X2ngO3l0N_9RJ7OKtTBlJ4YBuF/pub?w=809&h=521)\n",
        "\n",
        "上記のように、乗算ノードでは互いの数値を互い違いに掛け算し、加算ノードでは前段の値をそのまま使いながら逆の方向に計算を行うと、最終的に微分値が決定される。これが逆伝播法である。ポイントは以下の通り。\n",
        "\n",
        "* 偏微分値は出力側から逆順に計算してゆくことができる\n",
        "* 計算は各ノードの値のみを使えば良い\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhEqjSNybWR-",
        "colab_type": "text"
      },
      "source": [
        "## ReLUレイヤの実装\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vSvgNlyRTv8kiaVrxEk4MNumcGohtSS7DDfTkPpTAAUT-I0Ecjhi62dDU8RWQRIlz7eL4XBW2HoAP2g/pub?w=958&h=247)\n",
        "\n",
        "活性化関数ReLUの場合は入力値が０より大きい場合は、その値がそのまま渡される。このため、グラフの傾きすなわち微分値は１であり、逆伝播においては渡された値に１を掛けた値としてそのまま逆伝播させる。\n",
        "\n",
        "\n",
        "pythonでの実装としては、下記のようになる。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbOGTwl7neOP",
        "colab_type": "code",
        "outputId": "d30ea5a6-1bd1-4be8-daed-b8480947ce67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "from common.functions import *\n",
        "from common.util import im2col, col2im\n",
        "\n",
        "\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0  \n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "# ReLUレイヤーのコーディングサンプル\n",
        "x = np.array([[1.0,-1.2],[-2.2,1.3]])\n",
        "print(\"----------------\")\n",
        "print(\"もともとの入力値\")\n",
        "print(x)\n",
        "print(\"----------------\")\n",
        "print(\"mask=(x<=0)   マスク値  \")\n",
        "mask=(x<=0)\n",
        "print(mask)\n",
        "print(\"----------------\")\n",
        "print(\"x[mask]=0      Trueの部分をゼロで埋める\")\n",
        "x[mask]=0\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------\n",
            "もともとの入力値\n",
            "[[ 1.  -1.2]\n",
            " [-2.2  1.3]]\n",
            "----------------\n",
            "mask=(x<=0)   マスク値  \n",
            "[[False  True]\n",
            " [ True False]]\n",
            "----------------\n",
            "x[mask]=0      Trueの部分をゼロで埋める\n",
            "[[1.  0. ]\n",
            " [0.  1.3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjv9Jjb7sjJe",
        "colab_type": "text"
      },
      "source": [
        "## シグモイドレイヤの実装\n",
        "\n",
        "今回のMNSITデータ分析では利用しないが、シグモイド関数の逆伝播について記述する\n",
        "\n",
        "\n",
        "![シグモイド関数](https://docs.google.com/drawings/d/e/2PACX-1vSPiq7ffbs0PiyFDXrg93J1t3KdMq0eAnCoVC_JfD62LrszzR9t_4c3U76pF_SvNhDCxeKplvJrBIL_/pub?w=182&h=100)\n",
        "\n",
        "シグモイド関数の微分を計算グラフで解くと最終的に下記のようになる。\n",
        "\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vQbSo7K6xNPYZ6uZsEVr25lCTd-IyL_CvHxUBz_qnTGHR6_9ccFON4N9tWrGwZwPsJJJwKhqVtOu9yE/pub?w=476&h=224)\n",
        "\n",
        "\n",
        "実装としては下記の通り\n",
        "```\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "        return dx\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcXyEuBJOvZg",
        "colab_type": "text"
      },
      "source": [
        "## Affineレイヤの実装\n",
        "\n",
        "各ニューロンは複数からの信号と重み付けを受け取りそれらの総和を活性化関数に引き渡している。\n",
        "\n",
        "![パーセプトロン](https://docs.google.com/drawings/d/e/2PACX-1vSpMVD85wOprci70XqNYFpaA3gNI_rTRVezumjEJ6trAHQ6qMq7gPA-PH7bDzHfOkMb-pEKQXxSOvs_/pub?w=302&h=220)\n",
        "\n",
        "先程はこの活性化関数を一つのレイヤとして実装した。Affineレイヤはその前段として、各ノードからの値と重みを掛け合わせ、バイアスを付加する部分を受け持つ。\n",
        "\n",
        "\n",
        "* affineとは幾何学における写像を意味する。\n",
        "\n",
        "```\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W =W\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        \n",
        "        return dx\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk6CydMIYl5i",
        "colab_type": "text"
      },
      "source": [
        "## Softmax with Lossレイヤの実装\n",
        "ニューラルネットワークの最終段階としてソフトマックス関数による確信度の計算とそれを評価する損失関数のレイヤを同時に定義する。なお、ここでは損失関数を交差エントロピーとしている。\n",
        "\n",
        "\n",
        "```\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "        self.y = None # softmaxの出力\n",
        "        self.t = None # 教師データ\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "        \n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 教師データがone-hot-vectorの場合\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "        \n",
        "        return dx\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8t2eRU2cpbB",
        "colab_type": "text"
      },
      "source": [
        "## 全体実装\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vRz5JqHaZeJ2QZy31JlNOiROYOsYd5q1nZ29G79UH3MEM0cAN9zn_v717IeMl0_rUXsw82679O8aEmk/pub?w=599&h=413)\n",
        "\n",
        "隠れ層を５０とした２層のニューラルネットワークを実装する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1DwAqg0gg8j",
        "colab_type": "code",
        "outputId": "020426a2-897e-4ce9-b381-ccace012d6d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/deep-learning-from-scratch/ch04\n",
        "\n",
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "from common.layers import *\n",
        "from common.gradient import numerical_gradient\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "        # 重みの初期化\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "        \n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    # x:入力データ, t:教師データ\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "        \n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    # x:入力データ, t:教師データ\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "        \n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "        \n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 設定\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch/ch04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeqOtvwzgjW_",
        "colab_type": "code",
        "outputId": "df41d904-4c0d-4a17-969a-27455d3e7c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "# データの読み込み\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 勾配\n",
        "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "    \n",
        "    # 更新\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "    \n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading train-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n",
            "0.11236666666666667 0.1135\n",
            "0.7669833333333334 0.7718\n",
            "0.8752666666666666 0.8815\n",
            "0.89825 0.9019\n",
            "0.9079833333333334 0.9109\n",
            "0.9144166666666667 0.917\n",
            "0.9195166666666666 0.9221\n",
            "0.9234166666666667 0.9251\n",
            "0.92685 0.9282\n",
            "0.9301166666666667 0.9301\n",
            "0.9328166666666666 0.9335\n",
            "0.9352333333333334 0.9345\n",
            "0.9370666666666667 0.9368\n",
            "0.9393333333333334 0.9387\n",
            "0.9416166666666667 0.9405\n",
            "0.943 0.9426\n",
            "0.9447 0.9428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHSKcdTAh34r",
        "colab_type": "text"
      },
      "source": [
        "# 実装上の課題\n",
        "これまでのところで大まかなAIの仕組みについて学習を行った。ここではAIを実際に実装する場合に問題となる諸課題について概覧する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Nhb3Cbip3l",
        "colab_type": "text"
      },
      "source": [
        "## 勾配降下法の問題点\n",
        "\n",
        "勾配降下法によって最も損失関数が小さくなる値を求める場合、問題としてはその出発点によっては目標の最小値にたどり着けない点である。\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vQhdzzAYjQ8Uxgs4-7bZ1soV_wPt1M47ll436PPh2y6d-rOE9cU4voWgVO9QcMIFCq5V6-OV9D7DWbf/pub?w=791&h=386)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNxOjZlCkGnQ",
        "colab_type": "text"
      },
      "source": [
        "### SGD(確率的勾配降下法）\n",
        "先に実装した例は確率的勾配降下法と呼ばれる手法である。これは全体の中の一部をランダムに選び出すことで、計算の起点となる点Pの位置を変えることで、確率的に目標の近辺からスタートさせる事を目標としている。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHKb_BQxmkXk",
        "colab_type": "text"
      },
      "source": [
        "#### 標準的な探索方法\n",
        "\n",
        "基本的には微分値がマイナスとなる方向に予め定められた量を移動させることで、最適解を探索する。\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vRwN3IoFQ1PPyVor6NoQbXQohRqEc9S1SRLO7zHR2KbbgxkR7EpC-GUqUzKazvEsrUhJ3dH6M3Gb3Ze/pub?w=791&h=386)\n",
        "\n",
        "この予め定めらた量は学習率（Learning Rate）ηで示される。この学習率の設定は経験的に定められる。上図の場合では学習率が大きいため、一旦かなり最適解に近づくものの、その次では最適解を通り越してしまい、いわゆる振り子状態が長く続く点が問題となる。\n",
        "\n",
        "#### Momentumによる探索\n",
        "これは常にひつ前の移動量を保存しておき、その前回移動量の一定割合をマイナスに作用させる探索方法であり、これにより見かけ上は慣性的な力が加わることで、自由振り子状態を緩和させることができる。\n",
        "\n",
        "#### AdaGrad\n",
        "これは各学習段階の履歴を保存し、過去の学習量に比例して移動量を減らしてゆく手法である。\n",
        "\n",
        "#### Adam\n",
        "Momentum + AdaGradによる探索法\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNwK5Dh6wpQZ",
        "colab_type": "text"
      },
      "source": [
        "## 重みの初期値\n",
        "例題では重みの初期値はガウス分布を用いたが、代表的な初期値は２つ。\n",
        "\n",
        "### Xaivierの初期値\n",
        "　Xaivierの初期値は様々なニューラルネットで用いられている。sigmoid関数やtanh関数を活性化関数として用いる時、このXavierの初期値を用いるとよい。\n",
        "\n",
        "### Heの初期値\n",
        "　Heの初期値はReLU関数を活性化関数とするときに用いるとよい。ReLU関数を活性化関数としたモデルにXavierの初期値を用いるとアクティベーション分布に偏りが生じやすくなることが知られている。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwLF9myly9Bq",
        "colab_type": "text"
      },
      "source": [
        "## Batch Normalization\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vSa-QlDlMx_WFHsisso0ulsManhVjcWxVxWfbZtlVesNnlaSnlK2gOyLk-dS8DPbWuHMMUexEWTwhqL/pub?w=397&h=206)\n",
        "\n",
        "これはミニバッチ単位に入力データの値を平均がゼロ、分散が１となるように統計的に調整するレイヤーを挟み込むことで下記のような効果が得られる。\n",
        "* 学習が早く進む\n",
        "* 初期パラメータへの依存度が下がる\n",
        "* 過学習を抑制できる\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNsvfi0O01dO",
        "colab_type": "text"
      },
      "source": [
        "## 過学習への対応\n",
        "　過学習とは訓練データにフィットしすぎて未知データに対してはかえって認識率が低くなる状態をさす。この過学習を防ぐための仕組みとしてWeight DecayとDropoutについて述べる\n",
        "\n",
        "### Weight Decay\n",
        "　過学習の原因として重みの値が極端に大きくなる事が知られており、これに対応するほうほうとして構築された手法。  \n",
        "　損失関数に重みWを要素とした値を加えることで、大きな重みが損失を大きくするように調整する。\n",
        "\n",
        "### Drop Out\n",
        "\n",
        "![代替テキスト](https://docs.google.com/drawings/d/e/2PACX-1vRhsO9inUmkCqld72pxTJNfqejbccG7V0WeBBZq-TmtrEWpv_shAhVb_O-8KbRPD0FXDwxX99iIBhYj/pub?w=595&h=229)\n",
        "\n",
        "　途中のニューロンをミニバッチ毎にランダムに間引くことで、信号の経路を複数パターンで学習させる。その際に飛ばされたニューロンを代替するニューロンは余計に信号を学習する？　ことで全体の効率が上がる？　らしい。\n",
        "\n",
        "\n"
      ]
    }
  ]
}